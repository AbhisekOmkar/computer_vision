{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch and related packages\n",
    "import torch\n",
    "from torchvision import transforms, datasets, utils\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "\n",
    "# Math and plot utils\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Useful utilities\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Our model which we train\n",
    "from models.fast_scnn import FastSCNN\n",
    "\n",
    "# Custom Utilities\n",
    "from utils.dataset import IGVCDataset\n",
    "from utils.train_util import train_net\n",
    "from utils.common_utils import load_model, output_mask, save_model, img_to_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_CudaDeviceProperties(name='GeForce 920M', major=3, minor=5, total_memory=2004MB, multi_processor_count=2)\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "gpuid = 0\n",
    "print(torch.cuda.get_device_properties(gpuid))\n",
    "device = torch.device(f'cuda:{gpuid}' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_lanes(image, label):\n",
    "    mean = np.array([0.5, 0.5, 0.5])\n",
    "    std = np.array([0.5, 0.5, 0.5])\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    image = std * image + mean\n",
    "    image = np.clip(image, 0, 1)\n",
    "    label = label.numpy().transpose((1, 2, 0))\n",
    "    label = std * label + mean\n",
    "    label = np.clip(label, 0, 1)\n",
    "    plt.imshow(image, cmap='gray')\n",
    "    plt.imshow(label, cmap='jet', alpha=0.5)\n",
    "    plt.pause(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomResizedCrop(size=(480, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((480, 640)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 265, 'val': 201, 'test': 434}\n"
     ]
    }
   ],
   "source": [
    "dataloaders = {}\n",
    "datasets = {}\n",
    "datasizes = {}\n",
    "\n",
    "datasets['train'] = IGVCDataset(imgs_dir='data_train/images', labels_dir='data_train/labels', transform=train_transforms)\n",
    "dataloaders['train'] = torch.utils.data.DataLoader(datasets['train'], batch_size=4, shuffle=True, num_workers=2)\n",
    "datasizes['train'] = len(datasets['train'])\n",
    "\n",
    "datasets['val'] = IGVCDataset(imgs_dir='data_val/images', labels_dir='data_val/labels', transform=test_transforms)\n",
    "dataloaders['val'] = torch.utils.data.DataLoader(datasets['val'], batch_size=4, shuffle=True, num_workers=2)\n",
    "datasizes['val'] = len(datasets['val'])\n",
    "\n",
    "datasets['test'] = IGVCDataset(imgs_dir='data_test/images', labels_dir='data_test/labels', transform=test_transforms)\n",
    "dataloaders['test'] = torch.utils.data.DataLoader(datasets['test'], batch_size=4, shuffle=False, num_workers=2)\n",
    "datasizes['test'] = len(datasets['test'])\n",
    "\n",
    "print(datasizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastSCNN(in_channel=1, width_multiplier=0.5, num_classes=2, dropout_prob=0.5).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_model(model, './model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 0.5457 Acc: 210071.4075\n",
      "val Loss: 0.4796 Acc: 258975.2637\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 0.4095 Acc: 257153.0566\n",
      "val Loss: 0.3950 Acc: 256162.5323\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 0.3685 Acc: 264301.2642\n",
      "val Loss: 0.3518 Acc: 258935.1791\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 0.3590 Acc: 264866.3698\n",
      "val Loss: 0.3469 Acc: 268904.0100\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 0.3286 Acc: 265823.5887\n",
      "val Loss: 0.3189 Acc: 262056.4925\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 0.3241 Acc: 265632.4906\n",
      "val Loss: 0.3199 Acc: 272599.1542\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 0.3029 Acc: 264755.2302\n",
      "val Loss: 0.3054 Acc: 269595.0000\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 0.2838 Acc: 266674.1887\n",
      "val Loss: 0.2761 Acc: 268346.0995\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 0.2834 Acc: 266125.2038\n",
      "val Loss: 0.2837 Acc: 257345.7861\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 0.2916 Acc: 263048.9245\n",
      "val Loss: 0.2812 Acc: 258527.1791\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 0.2673 Acc: 262715.2491\n",
      "val Loss: 0.2688 Acc: 259644.0697\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 0.2645 Acc: 264370.4642\n",
      "val Loss: 0.2661 Acc: 263617.3582\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 0.2628 Acc: 265264.0642\n",
      "val Loss: 0.2596 Acc: 261668.2189\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 0.2606 Acc: 264715.4113\n",
      "val Loss: 0.2511 Acc: 264641.0448\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 0.2595 Acc: 266523.5887\n",
      "val Loss: 0.2713 Acc: 261532.8756\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 0.2582 Acc: 265046.8226\n",
      "val Loss: 0.2576 Acc: 260407.9602\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 0.2530 Acc: 266325.5962\n",
      "val Loss: 0.2690 Acc: 259253.7114\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 0.2679 Acc: 265350.7509\n",
      "val Loss: 0.2548 Acc: 263665.1095\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 0.2672 Acc: 265453.1849\n",
      "val Loss: 0.2515 Acc: 265143.5473\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 0.2591 Acc: 266205.9811\n",
      "val Loss: 0.2486 Acc: 263039.5771\n",
      "\n",
      "Training complete in 9m 40s\n",
      "Best val Acc: 0.248560\n",
      "Done Training.\n",
      "Training Done.\n"
     ]
    }
   ],
   "source": [
    "optimizer_ft = torch.optim.SGD(model.parameters(), lr=0.006, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer_ft, step_size=10, gamma=0.1)\n",
    "criterion = torch.nn.CrossEntropyLoss(torch.tensor([1, 80], dtype=torch.float).to(device))\n",
    "\n",
    "model = train_net(model, dataloaders, datasizes, criterion, optimizer_ft, exp_lr_scheduler, device, num_epochs=20)\n",
    "print('Training Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b863cc70d02b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m#show_lanes(utils.make_grid(img), utils.make_grid(label))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, hold, data, **kwargs)\u001b[0m\n\u001b[1;32m   3203\u001b[0m                         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3204\u001b[0m                         \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3205\u001b[0;31m                         **kwargs)\n\u001b[0m\u001b[1;32m   3206\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3207\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1853\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1854\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1855\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1857\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/miniconda3/envs/vision/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5485\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5487\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5488\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5489\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/vision/lib/python3.7/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    651\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    652\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 653\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    654\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(dataloaders['train'])\n",
    "img, label = dataiter.next()\n",
    "img, label = dataiter.next()\n",
    "img, label = dataiter.next()\n",
    "img, label = dataiter.next()\n",
    "plt.imshow(img[1])\n",
    "#show_lanes(utils.make_grid(img), utils.make_grid(label))\n",
    "plt.show()\n",
    "plt.imshow(img[2].permute(1,2,0))\n",
    "#show_lanes(utils.make_grid(img), utils.make_grid(label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    pred = output_mask(img, model, device)\n",
    "    plt.imshow(pred[1])\n",
    "    plt.show()\n",
    "    plt.imshow(pred[2])\n",
    "    plt.show()\n",
    "    #plt.imshow(img[0].detach().cpu().permute(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are as following:\n",
      "Time for 100 Images :  11.69179368019104 seconds\n",
      "FPS (GeForce 920M) :  8.553007582525698 fps\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    dataiter = iter(dataloaders['test'])\n",
    "    for i in range(100):\n",
    "        img, label = dataiter.next()\n",
    "        pred = output_mask(img, model, device)\n",
    "    end_time = time.time()\n",
    "\n",
    "print('Results are as following:')\n",
    "print('Time for 100 Images : ', end_time - start_time, 'seconds')\n",
    "print('FPS (GeForce 920M) : ', 100/(end_time - start_time), 'fps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to  ./model_gray\n"
     ]
    }
   ],
   "source": [
    "save_model(model, './model_gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((480, 640)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], \n",
    "                         std=[0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = img_to_mask('web_images/input/4.jpg', model, test_transforms, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(mask[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
