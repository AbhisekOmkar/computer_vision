{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, dilation=1, groups=1):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.activation = nn.ReLU(inplace=True)\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        if x.size()[2:] != (1, 1):\n",
    "            x = self.bn(x)\n",
    "        x = self.activation(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DSConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1, dilation=1):\n",
    "        super().__init__()\n",
    "        self.ds_conv = nn.Sequential(\n",
    "            ConvBlock(in_channels=in_channels, out_channels=in_channels, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=in_channels),\n",
    "            ConvBlock(in_channels=in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.ds_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InvertedResidual(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride, expand_ratio):\n",
    "        super().__init__()\n",
    "        assert stride in [1, 2]\n",
    "        \n",
    "        hidden_dim = round(in_channels * expand_ratio)\n",
    "        self.use_res_connect = stride == 1 and in_channels == out_channels\n",
    "        self.inv_res = nn.Sequential(\n",
    "            ConvBlock(in_channels=in_channels, out_channels=hidden_dim, kernel_size=1, stride=1, padding=0, dilation=1, groups=1),\n",
    "            ConvBlock(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, stride=stride, padding=1, dilation=1, groups=hidden_dim),\n",
    "            nn.Conv2d(in_channels=hidden_dim, out_channels=out_channels, kernel_size=1, stride=1, padding=0, dilation=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.use_res_connect:\n",
    "            return x + self.inv_res(x)\n",
    "        else:\n",
    "            return self.inv_res(x)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyramidPooling(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        inter_channels = in_channels // 4\n",
    "        self.conv1 = ConvBlock(in_channels=in_channels, out_channels=inter_channels, kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "        self.conv2= ConvBlock(in_channels=in_channels, out_channels=inter_channels, kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "        self.conv3 = ConvBlock(in_channels=in_channels, out_channels=inter_channels, kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "        self.conv4 = ConvBlock(in_channels=in_channels, out_channels=inter_channels, kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "        self.out_conv = ConvBlock(in_channels=2*in_channels, out_channels=out_channels, kernel_size=1, stride=1, padding=0, dilation=1, groups=1)\n",
    "        \n",
    "    def pool(self, x, size):\n",
    "        avgpool = nn.AdaptiveAvgPool2d(size)\n",
    "        return avgpool(x)\n",
    "\n",
    "    def upsample(self, x, size):\n",
    "        return F.interpolate(x, size, mode='bilinear', align_corners=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        fcn_feat_spatial_dim = x.size()[2:]\n",
    "        \n",
    "        pool1 = self.upsample(self.conv1(self.pool(x, 1)), fcn_feat_spatial_dim)\n",
    "        pool2 = self.upsample(self.conv1(self.pool(x, 2)), fcn_feat_spatial_dim)\n",
    "        pool3 = self.upsample(self.conv1(self.pool(x, 3)), fcn_feat_spatial_dim)\n",
    "        pool4 = self.upsample(self.conv1(self.pool(x, 6)), fcn_feat_spatial_dim)\n",
    "        \n",
    "        x = torch.cat([x, pool1, pool2, pool3, pool4], dim=1)\n",
    "        \n",
    "        x = self.out_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearnDownsampling(nn.Module):\n",
    "    def __init__(self, in_channels):\n",
    "        super().__init__()\n",
    "        self.learn_downsampling = nn.Sequential(\n",
    "            ConvBlock(in_channels=in_channels, out_channels=16, stride=2),\n",
    "            DSConv(in_channels=16, out_channels=24, kernel_size=3, stride=2, padding=1, dilation=1),\n",
    "            DSConv(in_channels=24, out_channels=32, kernel_size=3, stride=2, padding=1, dilation=1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.learn_downsampling(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GlobalFeatExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.inv_res_block1 = nn.Sequential(\n",
    "            InvertedResidual(in_channels=32, out_channels=32, stride=2, expand_ratio=6),\n",
    "            InvertedResidual(in_channels=32, out_channels=32, stride=1, expand_ratio=6),\n",
    "            InvertedResidual(in_channels=32, out_channels=32, stride=1, expand_ratio=6)\n",
    "        )\n",
    "        self.inv_res_block2 = nn.Sequential(\n",
    "            InvertedResidual(in_channels=32, out_channels=48, stride=2, expand_ratio=6),\n",
    "            InvertedResidual(in_channels=48, out_channels=48, stride=1, expand_ratio=6),\n",
    "            InvertedResidual(in_channels=48, out_channels=48, stride=1, expand_ratio=6)\n",
    "        )\n",
    "        self.inv_res_block3 = nn.Sequential(\n",
    "            InvertedResidual(in_channels=48, out_channels=64, stride=1, expand_ratio=6),\n",
    "            InvertedResidual(in_channels=64, out_channels=64, stride=1, expand_ratio=6),\n",
    "            InvertedResidual(in_channels=64, out_channels=64, stride=1, expand_ratio=6)\n",
    "        )\n",
    "        self.pyramid_pool = PyramidPooling(64, 64)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.inv_res_block3(self.inv_res_block2(self.inv_res_block1(x)))\n",
    "        return self.pyramid_pool(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatFusionModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = ConvBlock(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, dilation=1, groups=64)\n",
    "        self.conv_low_res = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.conv_high_res = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "    def forward(self, high_res_input, low_res_input):\n",
    "        final_size = high_res_input.size()[2:]\n",
    "        low_res_input = F.interpolate(low_res_input, size=final_size, mode='bilinear', align_corners=True)\n",
    "        low_res_input = self.conv1(low_res_input)\n",
    "        low_res_input = self.conv_low_res(low_res_input)\n",
    "        \n",
    "        high_res_input = self.conv_high_res(high_res_input)\n",
    "        fused = torch.add(high_res_input, low_res_input)\n",
    "        return self.relu(fused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier_conv = nn.Sequential(\n",
    "            DSConv(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, dilation=1),\n",
    "            DSConv(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1, dilation=1),\n",
    "            nn.Conv2d(in_channels=64, out_channels=num_classes, kernel_size=1, stride=1, padding=0, dilation=1, bias=True)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.classifier_conv(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 3 (Whole model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FastSCNN(nn.Module):\n",
    "    def __init__(self, in_channel, num_classes):\n",
    "        super().__init__()\n",
    "        self.learning_to_ds = LearnDownsampling(in_channel)\n",
    "        self.global_feat_ext = GlobalFeatExtractor()\n",
    "        self.feat_fuse = FeatFusionModule()\n",
    "        self.classifier = Classifier(num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        in_size = x.size()[2:]\n",
    "        shared = self.learning_to_ds(x)\n",
    "        x = self.global_feat_ext(shared)\n",
    "        x = self.feat_fuse(shared, x)\n",
    "        x = self.classifier(x)\n",
    "        x = F.interpolate(x, size=in_size, mode='bilinear', align_corners=True)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
